{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# add a path to sys.path\n",
    "sys.path.append('/home/wenxinjiang/tf-maskformer/')\n",
    "sys.path.append('/home/wenxinjiang/tf-maskformer/models/')\n",
    "sys.path.append('/home/wenxinjiang/tf-maskformer/models/official/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from official.projects.maskformer.dataloaders import panoptic_input\n",
    "from official.projects.detr.dataloaders import detr_input\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from official.core import train_utils\n",
    "\n",
    "from official.projects.detr.tasks import detection\n",
    "\n",
    "\n",
    "from official.core import task_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INPUT_PATH_BASE = 'gs://cam2-datasets/coco'\n",
    "COCO_ANNOTATION_PATH_BASE = 'gs://cam2-datasets/annotations'\n",
    "COCO_TRAIN_EXAMPLES = 118287\n",
    "COCO_VAL_EXAMPLES = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = COCO_INPUT_PATH_BASE  # specify the filepath to tfrecord\n",
    "# get list of tfrecord files\n",
    "file_paths = tf.io.gfile.glob(tfrecord_path + \"/*.tfrecord\")\n",
    "decoder = panoptic_input.TfExampleDecoder()\n",
    "image_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_yolo_input_task():\n",
    "  # with tf.device('/CPU:0'):\n",
    "  experiment = \"detr_coco_tfrecord\"\n",
    "  config_path = [\"/home/wenxinjiang/tf-maskformer/models/official/projects/detr/configs/detr_tpu_v3_640.yaml\"]\n",
    "  # config_path = [\"yolo/configs/experiments/yolov4-csp/tpu/640.yaml\"]\n",
    "  # config_path = [\"yolo/configs/experiments/yolov4-csp-anchor-free/tpu/640-cstm2.yaml\"]\n",
    "\n",
    "  config = train_utils.ParseConfigOptions(\n",
    "      experiment=experiment, config_file=config_path)\n",
    "  params = train_utils.parse_configuration(config)\n",
    "  config = params.task\n",
    "\n",
    "  # anchor gen testing\n",
    "  # config.model.boxes = None\n",
    "\n",
    "  task = task_factory.get_task(params.task)\n",
    "\n",
    "  config.train_data.global_batch_size = 1\n",
    "  config.validation_data.global_batch_size = 1\n",
    "\n",
    "  config.train_data.dtype = 'float32'\n",
    "  config.validation_data.dtype = 'float32'\n",
    "\n",
    "  config.validation_data.shuffle_buffer_size = 1\n",
    "  config.train_data.shuffle_buffer_size = 1\n",
    "\n",
    "\n",
    "  config.train_data.input_path = COCO_INPUT_PATH_BASE+'/train*'\n",
    "  config.validation_data.input_path = COCO_INPUT_PATH_BASE+'/val*'\n",
    "\n",
    "  with tf.device('/CPU:0'):\n",
    "    train_data = task.build_inputs(config.train_data)\n",
    "    test_data = task.build_inputs(config.validation_data)\n",
    "  return train_data, test_data, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 16:55:04.579863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/envs/maskformer/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-08-26 16:55:04.579897: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-26 16:55:04.579914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (compute-intensive-1): /proc/driver/nvidia/version does not exist\n",
      "2023-08-26 16:55:04.580207: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "dataset, dsp, config = test_yolo_input_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_tf_format(boxes):\n",
    "    tf_boxes = []\n",
    "    for box in boxes:\n",
    "        x1, y1, width, height = box\n",
    "        tf_boxes.append([y1, x1, y1 + height, x1 + width])\n",
    "    return tf.convert_to_tensor(tf_boxes, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes_on_image(ax, image, boxes):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes on image.\n",
    "    Args:\n",
    "    - ax: A matplotlib axis to draw upon.\n",
    "    - image: A [H, W, 3] RGB image.\n",
    "    - boxes: A list of bounding boxes in the format (cx, cy, w, h).\n",
    "    \"\"\"\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for box in boxes:\n",
    "        # Convert (cx, cy, w, h) to (x_min, y_min, x_max, y_max)\n",
    "        cy, cx, w, h = box\n",
    "        x_min, y_min = int((cx - w / 2) * image.shape[1]), int((cy - h / 2) * image.shape[0])\n",
    "        x_max, y_max = int((cx + w / 2) * image.shape[1]), int((cy + h / 2) * image.shape[0])\n",
    "\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "def test_yolo_pipeline(is_training=True, num=5):\n",
    "    dataset, dsp, config = test_yolo_input_task()  # assuming this function provides required data\n",
    "\n",
    "    data = dataset if is_training else dsp\n",
    "    data = data.take(num)\n",
    "    for l, (i, j) in enumerate(data):\n",
    "        for shind in range(1):  # loop runs only once\n",
    "            fig, axe = plt.subplots(1, 2)\n",
    "\n",
    "            image = i[shind].numpy()\n",
    "            # Denormalize the image from [0,1] to [0,255]\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            boxes = j[\"boxes\"][shind].numpy()\n",
    "\n",
    "            draw_bounding_boxes_on_image(axe[0], image, boxes)\n",
    "\n",
    "            fig.set_size_inches(18.5, 6.5, forward=True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"test{l}.png\")\n",
    "            plt.show()\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Axes' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_yolo_pipeline()\n",
      "Cell \u001b[0;32mIn[56], line 40\u001b[0m, in \u001b[0;36mtest_yolo_pipeline\u001b[0;34m(is_training, num)\u001b[0m\n\u001b[1;32m     37\u001b[0m image \u001b[39m=\u001b[39m (image \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[1;32m     38\u001b[0m boxes \u001b[39m=\u001b[39m j[\u001b[39m\"\u001b[39m\u001b[39mboxes\u001b[39m\u001b[39m\"\u001b[39m][shind]\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m---> 40\u001b[0m draw_bounding_boxes_on_image(axe[\u001b[39m0\u001b[39;49m], image, boxes)\n\u001b[1;32m     42\u001b[0m fig\u001b[39m.\u001b[39mset_size_inches(\u001b[39m18.5\u001b[39m, \u001b[39m6.5\u001b[39m, forward\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Axes' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_yolo_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
