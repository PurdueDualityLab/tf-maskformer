2023-10-09 16:02:02.018134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-10-09 16:02:02.148872: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-10-09 16:02:02.152160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-10-09 16:02:02.152198: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-10-09 16:02:02.858234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-10-09 16:02:02.858315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-10-09 16:02:02.858329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2023-10-09 16:02:04.655396: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/envs/maskformer/lib/python3.9/site-packages/cv2/../../lib64:
2023-10-09 16:02:04.655440: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2023-10-09 16:02:04.655462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (compute-intensive-1): /proc/driver/nvidia/version does not exist
I1009 16:02:04.665750 140612642072384 train_utils.py:359] Final experiment parameters:
{'runtime': {'all_reduce_alg': None,
             'batchnorm_spatial_persistent': False,
             'dataset_num_private_threads': None,
             'default_shard_dim': -1,
             'distribution_strategy': 'mirrored',
             'enable_xla': False,
             'gpu_thread_mode': None,
             'loss_scale': None,
             'mixed_precision_dtype': 'float32',
             'num_cores_per_replica': 1,
             'num_gpus': 0,
             'num_packs': 1,
             'per_gpu_thread_count': 0,
             'run_eagerly': False,
             'task_index': -1,
             'tpu': None,
             'tpu_enable_xla_dynamic_padder': None,
             'worker_hosts': None},
 'task': {'allow_image_summary': False,
          'annotation_file': '/home/vishalpurohit55595/wexin_detr/tf-maskformer/annotations/instances_val2017.json',
          'differential_privacy_config': None,
          'init_checkpoint': '',
          'init_checkpoint_modules': 'backbone',
          'losses': {'background_cls_weight': 0.1,
                     'class_offset': 0,
                     'l2_weight_decay': 0.0001,
                     'lambda_box': 5.0,
                     'lambda_cls': 1.0,
                     'lambda_giou': 2.0},
          'model': {'backbone': {'resnet': {'bn_trainable': False,
                                            'depth_multiplier': 1.0,
                                            'model_id': 50,
                                            'replace_stem_max_pool': False,
                                            'resnetd_shortcut': False,
                                            'scale_stem': True,
                                            'se_ratio': 0.0,
                                            'stem_type': 'v0',
                                            'stochastic_depth_drop_rate': 0.0},
                                 'type': 'resnet'},
                    'backbone_endpoint_name': '5',
                    'hidden_size': 256,
                    'input_size': [1333, 1333, 3],
                    'norm_activation': {'activation': 'relu',
                                        'norm_epsilon': 0.001,
                                        'norm_momentum': 0.99,
                                        'use_sync_bn': True},
                    'num_classes': 91,
                    'num_decoder_layers': 6,
                    'num_encoder_layers': 6,
                    'num_queries': 100},
          'name': None,
          'per_category_metrics': False,
          'train_data': {'apply_tf_data_service_before_batching': False,
                         'block_length': 1,
                         'cache': False,
                         'cycle_length': None,
                         'decoder': {'simple_decoder': {'attribute_names': [],
                                                        'mask_binarize_threshold': None,
                                                        'regenerate_source_id': False},
                                     'type': 'simple_decoder'},
                         'deterministic': None,
                         'drop_remainder': True,
                         'dtype': 'bfloat16',
                         'enable_shared_tf_data_service_between_parallel_trainers': False,
                         'enable_tf_data_service': False,
                         'file_type': 'tfrecord',
                         'global_batch_size': 2,
                         'input_path': 'gs://cam2-datasets/coco/train*',
                         'is_training': True,
                         'prefetch_buffer_size': None,
                         'seed': None,
                         'sharding': True,
                         'shuffle_buffer_size': 1000,
                         'tf_data_service_address': None,
                         'tf_data_service_job_name': None,
                         'tfds_as_supervised': False,
                         'tfds_data_dir': '',
                         'tfds_name': '',
                         'tfds_skip_decoding_feature': '',
                         'tfds_split': 'train',
                         'trainer_id': None},
          'validation_data': {'apply_tf_data_service_before_batching': False,
                              'block_length': 1,
                              'cache': False,
                              'cycle_length': None,
                              'decoder': {'simple_decoder': {'attribute_names': [],
                                                             'mask_binarize_threshold': None,
                                                             'regenerate_source_id': False},
                                          'type': 'simple_decoder'},
                              'deterministic': None,
                              'drop_remainder': False,
                              'dtype': 'bfloat16',
                              'enable_shared_tf_data_service_between_parallel_trainers': False,
                              'enable_tf_data_service': False,
                              'file_type': 'tfrecord',
                              'global_batch_size': 2,
                              'input_path': 'gs://cam2-datasets/coco/val*',
                              'is_training': False,
                              'prefetch_buffer_size': None,
                              'seed': None,
                              'sharding': True,
                              'shuffle_buffer_size': 10000,
                              'tf_data_service_address': None,
                              'tf_data_service_job_name': None,
                              'tfds_as_supervised': False,
                              'tfds_data_dir': '',
                              'tfds_name': '',
                              'tfds_skip_decoding_feature': '',
                              'tfds_split': 'train',
                              'trainer_id': None}},
 'trainer': {'allow_tpu_summary': False,
             'best_checkpoint_eval_metric': 'AP',
             'best_checkpoint_export_subdir': 'best_ckpt',
             'best_checkpoint_metric_comp': 'higher',
             'checkpoint_interval': 1848,
             'continuous_eval_timeout': 3600,
             'eval_tf_function': True,
             'eval_tf_while_loop': False,
             'loss_upper_bound': 1000000.0,
             'max_to_keep': 1,
             'optimizer_config': {'ema': None,
                                  'learning_rate': {'stepwise': {'boundaries': [369600],
                                                                 'name': 'PiecewiseConstantDecay',
                                                                 'offset': 0,
                                                                 'values': [0.0001,
                                                                            1e-05]},
                                                    'type': 'stepwise'},
                                  'optimizer': {'detr_adamw': {'amsgrad': False,
                                                               'beta_1': 0.9,
                                                               'beta_2': 0.999,
                                                               'clipnorm': None,
                                                               'clipvalue': None,
                                                               'epsilon': 1e-07,
                                                               'exclude_from_weight_decay': None,
                                                               'global_clipnorm': 0.1,
                                                               'gradient_clip_norm': 0.0,
                                                               'include_in_weight_decay': None,
                                                               'name': 'AdamWeightDecay',
                                                               'weight_decay_rate': 0.0001},
                                                'type': 'detr_adamw'},
                                  'warmup': {'type': None}},
             'preemption_on_demand_checkpoint': True,
             'recovery_begin_steps': 0,
             'recovery_max_trials': 0,
             'steps_per_loop': 1848,
             'summary_interval': 1848,
             'train_steps': 554400,
             'train_tf_function': True,
             'train_tf_while_loop': True,
             'validation_interval': 9240,
             'validation_steps': 78,
             'validation_summary_subdir': 'validation'}}
I1009 16:02:04.666059 140612642072384 train_utils.py:371] Saving experiment configuration to gs://cam2-models/detr_exp5/params.yaml
2023-10-09 16:02:05.266760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W1009 16:02:05.270351 140612642072384 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I1009 16:02:05.346027 140612642072384 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I1009 16:02:05.722980 140612642072384 train_utils.py:98] Created the best checkpoint exporter. data_dir: gs://cam2-models/detr_exp5, export_subdir: best_ckpt, metric_name: AP
I1009 16:02:05.723689 140612642072384 train_utils.py:245] Running default trainer.
I1009 16:02:07.062749 140612642072384 legacy_adamw.py:56] AdamWeightDecay gradient_clip_norm=0.000000
WARNING:tensorflow:From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
W1009 16:02:07.487972 140612642072384 deprecation.py:350] From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
I1009 16:02:09.533879 140612642072384 controller.py:431] restoring or initializing model...
I1009 16:02:09.534058 140612642072384 train_lib.py:255] Starts to execute mode: train
I1009 16:02:09.538373 140612642072384 controller.py:256] train | step:      0 | training until step 554400...
2023-10-09 16:02:10.708615: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
2023-10-09 16:02:13.289 | DEBUG    | tensorflow.python.autograph.operators.control_flow:_py_if_stmt:1416 - target_shape is [2, 100, 256]
2023-10-09 16:02:16.241 | DEBUG    | tensorflow.python.autograph.operators.control_flow:_py_if_stmt:1416 - target_shape is [2, 100, 256]
WARNING:tensorflow:From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: calling foldl_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldl(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldl(fn, elems))
W1009 16:02:17.850119 140604931561216 deprecation.py:623] From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1176: calling foldl_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldl(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldl(fn, elems))
WARNING:tensorflow:From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.while_loop(c, b, vars, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))
W1009 16:02:18.074046 140604931561216 deprecation.py:623] From /opt/conda/envs/maskformer/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:458: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.while_loop(c, b, vars, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))
restoring or initializing model...
train | step:      0 | training until step 554400...
Gradient norm for param conv2d/kernel:0: Tensor("norm/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d/kernel:0: Tensor("norm_1/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d_1/kernel:0: Tensor("norm_2/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d_2/kernel:0: Tensor("norm_3/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d_3/kernel:0: Tensor("norm_4/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_1/conv2d/kernel:0: Tensor("norm_5/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_1/conv2d_1/kernel:0: Tensor("norm_6/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_1/conv2d_2/kernel:0: Tensor("norm_7/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_2/conv2d/kernel:0: Tensor("norm_8/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_2/conv2d_1/kernel:0: Tensor("norm_9/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_2/conv2d_2/kernel:0: Tensor("norm_10/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d/kernel:0: Tensor("norm_11/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d_1/kernel:0: Tensor("norm_12/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d_2/kernel:0: Tensor("norm_13/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d_3/kernel:0: Tensor("norm_14/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_4/conv2d/kernel:0: Tensor("norm_15/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_4/conv2d_1/kernel:0: Tensor("norm_16/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_4/conv2d_2/kernel:0: Tensor("norm_17/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_5/conv2d/kernel:0: Tensor("norm_18/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_5/conv2d_1/kernel:0: Tensor("norm_19/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_5/conv2d_2/kernel:0: Tensor("norm_20/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_6/conv2d/kernel:0: Tensor("norm_21/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_6/conv2d_1/kernel:0: Tensor("norm_22/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_6/conv2d_2/kernel:0: Tensor("norm_23/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d/kernel:0: Tensor("norm_24/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d_1/kernel:0: Tensor("norm_25/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d_2/kernel:0: Tensor("norm_26/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d_3/kernel:0: Tensor("norm_27/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_8/conv2d/kernel:0: Tensor("norm_28/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_8/conv2d_1/kernel:0: Tensor("norm_29/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_8/conv2d_2/kernel:0: Tensor("norm_30/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_9/conv2d/kernel:0: Tensor("norm_31/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_9/conv2d_1/kernel:0: Tensor("norm_32/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_9/conv2d_2/kernel:0: Tensor("norm_33/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_10/conv2d/kernel:0: Tensor("norm_34/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_10/conv2d_1/kernel:0: Tensor("norm_35/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_10/conv2d_2/kernel:0: Tensor("norm_36/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_11/conv2d/kernel:0: Tensor("norm_37/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_11/conv2d_1/kernel:0: Tensor("norm_38/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_11/conv2d_2/kernel:0: Tensor("norm_39/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_12/conv2d/kernel:0: Tensor("norm_40/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_12/conv2d_1/kernel:0: Tensor("norm_41/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_12/conv2d_2/kernel:0: Tensor("norm_42/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d/kernel:0: Tensor("norm_43/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d_1/kernel:0: Tensor("norm_44/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d_2/kernel:0: Tensor("norm_45/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d_3/kernel:0: Tensor("norm_46/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_14/conv2d/kernel:0: Tensor("norm_47/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_14/conv2d_1/kernel:0: Tensor("norm_48/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_14/conv2d_2/kernel:0: Tensor("norm_49/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_15/conv2d/kernel:0: Tensor("norm_50/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_15/conv2d_1/kernel:0: Tensor("norm_51/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_15/conv2d_2/kernel:0: Tensor("norm_52/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/conv2d/kernel:0: Tensor("norm_53/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/conv2d/bias:0: Tensor("norm_54/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/query/kernel:0: Tensor("norm_55/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/key/kernel:0: Tensor("norm_56/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/value/kernel:0: Tensor("norm_57/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/attention_output/kernel:0: Tensor("norm_58/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention_layer_norm/gamma:0: Tensor("norm_59/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention_layer_norm/beta:0: Tensor("norm_60/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/intermediate/kernel:0: Tensor("norm_61/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/intermediate/bias:0: Tensor("norm_62/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output/kernel:0: Tensor("norm_63/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output/bias:0: Tensor("norm_64/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output_layer_norm/gamma:0: Tensor("norm_65/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output_layer_norm/beta:0: Tensor("norm_66/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/query/kernel:0: Tensor("norm_67/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/key/kernel:0: Tensor("norm_68/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/value/kernel:0: Tensor("norm_69/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/attention_output/kernel:0: Tensor("norm_70/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention_layer_norm/gamma:0: Tensor("norm_71/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention_layer_norm/beta:0: Tensor("norm_72/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/intermediate/kernel:0: Tensor("norm_73/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/intermediate/bias:0: Tensor("norm_74/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output/kernel:0: Tensor("norm_75/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output/bias:0: Tensor("norm_76/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output_layer_norm/gamma:0: Tensor("norm_77/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output_layer_norm/beta:0: Tensor("norm_78/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/query/kernel:0: Tensor("norm_79/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/key/kernel:0: Tensor("norm_80/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/value/kernel:0: Tensor("norm_81/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/attention_output/kernel:0: Tensor("norm_82/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention_layer_norm/gamma:0: Tensor("norm_83/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention_layer_norm/beta:0: Tensor("norm_84/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/intermediate/kernel:0: Tensor("norm_85/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/intermediate/bias:0: Tensor("norm_86/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output/kernel:0: Tensor("norm_87/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output/bias:0: Tensor("norm_88/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output_layer_norm/gamma:0: Tensor("norm_89/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output_layer_norm/beta:0: Tensor("norm_90/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/query/kernel:0: Tensor("norm_91/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/key/kernel:0: Tensor("norm_92/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/value/kernel:0: Tensor("norm_93/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/attention_output/kernel:0: Tensor("norm_94/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention_layer_norm/gamma:0: Tensor("norm_95/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention_layer_norm/beta:0: Tensor("norm_96/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/intermediate/kernel:0: Tensor("norm_97/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/intermediate/bias:0: Tensor("norm_98/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output/kernel:0: Tensor("norm_99/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output/bias:0: Tensor("norm_100/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output_layer_norm/gamma:0: Tensor("norm_101/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output_layer_norm/beta:0: Tensor("norm_102/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/query/kernel:0: Tensor("norm_103/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/key/kernel:0: Tensor("norm_104/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/value/kernel:0: Tensor("norm_105/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/attention_output/kernel:0: Tensor("norm_106/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention_layer_norm/gamma:0: Tensor("norm_107/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention_layer_norm/beta:0: Tensor("norm_108/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/intermediate/kernel:0: Tensor("norm_109/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/intermediate/bias:0: Tensor("norm_110/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output/kernel:0: Tensor("norm_111/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output/bias:0: Tensor("norm_112/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output_layer_norm/gamma:0: Tensor("norm_113/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output_layer_norm/beta:0: Tensor("norm_114/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/query/kernel:0: Tensor("norm_115/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/key/kernel:0: Tensor("norm_116/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/value/kernel:0: Tensor("norm_117/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/attention_output/kernel:0: Tensor("norm_118/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention_layer_norm/gamma:0: Tensor("norm_119/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention_layer_norm/beta:0: Tensor("norm_120/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/intermediate/kernel:0: Tensor("norm_121/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/intermediate/bias:0: Tensor("norm_122/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output/kernel:0: Tensor("norm_123/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output/bias:0: Tensor("norm_124/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output_layer_norm/gamma:0: Tensor("norm_125/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output_layer_norm/beta:0: Tensor("norm_126/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_normalization/gamma:0: Tensor("norm_127/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_normalization/beta:0: Tensor("norm_128/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/query/kernel:0: Tensor("norm_129/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/key/kernel:0: Tensor("norm_130/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/value/kernel:0: Tensor("norm_131/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/attention_output/kernel:0: Tensor("norm_132/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention_layer_norm/gamma:0: Tensor("norm_133/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention_layer_norm/beta:0: Tensor("norm_134/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/query/kernel:0: Tensor("norm_135/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/key/kernel:0: Tensor("norm_136/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/value/kernel:0: Tensor("norm_137/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/attention_output/kernel:0: Tensor("norm_138/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_139/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec_output_layer_norm/beta:0: Tensor("norm_140/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/intermediate/kernel:0: Tensor("norm_141/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/intermediate/bias:0: Tensor("norm_142/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output/kernel:0: Tensor("norm_143/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output/bias:0: Tensor("norm_144/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output_layer_norm/gamma:0: Tensor("norm_145/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output_layer_norm/beta:0: Tensor("norm_146/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/query/kernel:0: Tensor("norm_147/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/key/kernel:0: Tensor("norm_148/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/value/kernel:0: Tensor("norm_149/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/attention_output/kernel:0: Tensor("norm_150/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention_layer_norm/gamma:0: Tensor("norm_151/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention_layer_norm/beta:0: Tensor("norm_152/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/query/kernel:0: Tensor("norm_153/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/key/kernel:0: Tensor("norm_154/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/value/kernel:0: Tensor("norm_155/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/attention_output/kernel:0: Tensor("norm_156/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_157/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec_output_layer_norm/beta:0: Tensor("norm_158/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/intermediate/kernel:0: Tensor("norm_159/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/intermediate/bias:0: Tensor("norm_160/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output/kernel:0: Tensor("norm_161/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output/bias:0: Tensor("norm_162/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output_layer_norm/gamma:0: Tensor("norm_163/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output_layer_norm/beta:0: Tensor("norm_164/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/query/kernel:0: Tensor("norm_165/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/key/kernel:0: Tensor("norm_166/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/value/kernel:0: Tensor("norm_167/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/attention_output/kernel:0: Tensor("norm_168/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention_layer_norm/gamma:0: Tensor("norm_169/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention_layer_norm/beta:0: Tensor("norm_170/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/query/kernel:0: Tensor("norm_171/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/key/kernel:0: Tensor("norm_172/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/value/kernel:0: Tensor("norm_173/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/attention_output/kernel:0: Tensor("norm_174/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_175/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec_output_layer_norm/beta:0: Tensor("norm_176/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/intermediate/kernel:0: Tensor("norm_177/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/intermediate/bias:0: Tensor("norm_178/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output/kernel:0: Tensor("norm_179/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output/bias:0: Tensor("norm_180/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output_layer_norm/gamma:0: Tensor("norm_181/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output_layer_norm/beta:0: Tensor("norm_182/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/query/kernel:0: Tensor("norm_183/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/key/kernel:0: Tensor("norm_184/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/value/kernel:0: Tensor("norm_185/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/attention_output/kernel:0: Tensor("norm_186/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention_layer_norm/gamma:0: Tensor("norm_187/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention_layer_norm/beta:0: Tensor("norm_188/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/query/kernel:0: Tensor("norm_189/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/key/kernel:0: Tensor("norm_190/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/value/kernel:0: Tensor("norm_191/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/attention_output/kernel:0: Tensor("norm_192/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_193/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec_output_layer_norm/beta:0: Tensor("norm_194/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/intermediate/kernel:0: Tensor("norm_195/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/intermediate/bias:0: Tensor("norm_196/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output/kernel:0: Tensor("norm_197/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output/bias:0: Tensor("norm_198/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output_layer_norm/gamma:0: Tensor("norm_199/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output_layer_norm/beta:0: Tensor("norm_200/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/query/kernel:0: Tensor("norm_201/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/key/kernel:0: Tensor("norm_202/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/value/kernel:0: Tensor("norm_203/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/attention_output/kernel:0: Tensor("norm_204/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention_layer_norm/gamma:0: Tensor("norm_205/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention_layer_norm/beta:0: Tensor("norm_206/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
2023-10-09 16:02:30.641 | DEBUG    | tensorflow.python.autograph.operators.control_flow:_py_if_stmt:1416 - target_shape is [2, 100, 256]
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec/query/kernel:0: Tensor("norm_207/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec/key/kernel:0: Tensor("norm_208/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec/value/kernel:0: Tensor("norm_209/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec/attention_output/kernel:0: Tensor("norm_210/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_211/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec_output_layer_norm/beta:0: Tensor("norm_212/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/intermediate/kernel:0: Tensor("norm_213/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/intermediate/bias:0: Tensor("norm_214/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/output/kernel:0: Tensor("norm_215/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/output/bias:0: Tensor("norm_216/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/output_layer_norm/gamma:0: Tensor("norm_217/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/output_layer_norm/beta:0: Tensor("norm_218/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/self_attention/query/kernel:0: Tensor("norm_219/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/self_attention/key/kernel:0: Tensor("norm_220/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/self_attention/value/kernel:0: Tensor("norm_221/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/self_attention/attention_output/kernel:0: Tensor("norm_222/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/self_attention_layer_norm/gamma:0: Tensor("norm_223/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/self_attention_layer_norm/beta:0: Tensor("norm_224/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/attention/encdec/query/kernel:0: Tensor("norm_225/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/attention/encdec/key/kernel:0: Tensor("norm_226/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/attention/encdec/value/kernel:0: Tensor("norm_227/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/attention/encdec/attention_output/kernel:0: Tensor("norm_228/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_229/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/attention/encdec_output_layer_norm/beta:0: Tensor("norm_230/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/intermediate/kernel:0: Tensor("norm_231/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/intermediate/bias:0: Tensor("norm_232/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/output/kernel:0: Tensor("norm_233/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/output/bias:0: Tensor("norm_234/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/output_layer_norm/gamma:0: Tensor("norm_235/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_5/output_layer_norm/beta:0: Tensor("norm_236/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_normalization_1/gamma:0: Tensor("norm_237/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_normalization_1/beta:0: Tensor("norm_238/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/cls_dense/kernel:0: Tensor("norm_239/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/cls_dense/bias:0: Tensor("norm_240/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/box_dense_0/kernel:0: Tensor("norm_241/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/box_dense_0/bias:0: Tensor("norm_242/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/box_dense_1/kernel:0: Tensor("norm_243/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/box_dense_1/bias:0: Tensor("norm_244/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/box_dense_2/kernel:0: Tensor("norm_245/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/box_dense_2/bias:0: Tensor("norm_246/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/detr/query_embeddings:0: Tensor("norm_247/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param conv2d/kernel:0: Tensor("norm/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d/kernel:0: Tensor("norm_1/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d_1/kernel:0: Tensor("norm_2/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d_2/kernel:0: Tensor("norm_3/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block/conv2d_3/kernel:0: Tensor("norm_4/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_1/conv2d/kernel:0: Tensor("norm_5/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_1/conv2d_1/kernel:0: Tensor("norm_6/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_1/conv2d_2/kernel:0: Tensor("norm_7/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_2/conv2d/kernel:0: Tensor("norm_8/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_2/conv2d_1/kernel:0: Tensor("norm_9/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_2/conv2d_2/kernel:0: Tensor("norm_10/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d/kernel:0: Tensor("norm_11/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d_1/kernel:0: Tensor("norm_12/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d_2/kernel:0: Tensor("norm_13/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_3/conv2d_3/kernel:0: Tensor("norm_14/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_4/conv2d/kernel:0: Tensor("norm_15/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_4/conv2d_1/kernel:0: Tensor("norm_16/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_4/conv2d_2/kernel:0: Tensor("norm_17/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_5/conv2d/kernel:0: Tensor("norm_18/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_5/conv2d_1/kernel:0: Tensor("norm_19/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_5/conv2d_2/kernel:0: Tensor("norm_20/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_6/conv2d/kernel:0: Tensor("norm_21/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_6/conv2d_1/kernel:0: Tensor("norm_22/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_6/conv2d_2/kernel:0: Tensor("norm_23/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d/kernel:0: Tensor("norm_24/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d_1/kernel:0: Tensor("norm_25/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d_2/kernel:0: Tensor("norm_26/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_7/conv2d_3/kernel:0: Tensor("norm_27/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_8/conv2d/kernel:0: Tensor("norm_28/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_8/conv2d_1/kernel:0: Tensor("norm_29/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_8/conv2d_2/kernel:0: Tensor("norm_30/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_9/conv2d/kernel:0: Tensor("norm_31/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_9/conv2d_1/kernel:0: Tensor("norm_32/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_9/conv2d_2/kernel:0: Tensor("norm_33/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_10/conv2d/kernel:0: Tensor("norm_34/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_10/conv2d_1/kernel:0: Tensor("norm_35/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_10/conv2d_2/kernel:0: Tensor("norm_36/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_11/conv2d/kernel:0: Tensor("norm_37/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_11/conv2d_1/kernel:0: Tensor("norm_38/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_11/conv2d_2/kernel:0: Tensor("norm_39/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_12/conv2d/kernel:0: Tensor("norm_40/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_12/conv2d_1/kernel:0: Tensor("norm_41/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_12/conv2d_2/kernel:0: Tensor("norm_42/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d/kernel:0: Tensor("norm_43/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d_1/kernel:0: Tensor("norm_44/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d_2/kernel:0: Tensor("norm_45/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_13/conv2d_3/kernel:0: Tensor("norm_46/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_14/conv2d/kernel:0: Tensor("norm_47/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_14/conv2d_1/kernel:0: Tensor("norm_48/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_14/conv2d_2/kernel:0: Tensor("norm_49/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_15/conv2d/kernel:0: Tensor("norm_50/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_15/conv2d_1/kernel:0: Tensor("norm_51/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param bottleneck_block_15/conv2d_2/kernel:0: Tensor("norm_52/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/conv2d/kernel:0: Tensor("norm_53/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr/conv2d/bias:0: Tensor("norm_54/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/query/kernel:0: Tensor("norm_55/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/key/kernel:0: Tensor("norm_56/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/value/kernel:0: Tensor("norm_57/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention/attention_output/kernel:0: Tensor("norm_58/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention_layer_norm/gamma:0: Tensor("norm_59/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/self_attention_layer_norm/beta:0: Tensor("norm_60/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/intermediate/kernel:0: Tensor("norm_61/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/intermediate/bias:0: Tensor("norm_62/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output/kernel:0: Tensor("norm_63/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output/bias:0: Tensor("norm_64/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output_layer_norm/gamma:0: Tensor("norm_65/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_0/output_layer_norm/beta:0: Tensor("norm_66/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/query/kernel:0: Tensor("norm_67/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/key/kernel:0: Tensor("norm_68/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/value/kernel:0: Tensor("norm_69/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention/attention_output/kernel:0: Tensor("norm_70/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention_layer_norm/gamma:0: Tensor("norm_71/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/self_attention_layer_norm/beta:0: Tensor("norm_72/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/intermediate/kernel:0: Tensor("norm_73/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/intermediate/bias:0: Tensor("norm_74/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output/kernel:0: Tensor("norm_75/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output/bias:0: Tensor("norm_76/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output_layer_norm/gamma:0: Tensor("norm_77/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_1/output_layer_norm/beta:0: Tensor("norm_78/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/query/kernel:0: Tensor("norm_79/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/key/kernel:0: Tensor("norm_80/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/value/kernel:0: Tensor("norm_81/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention/attention_output/kernel:0: Tensor("norm_82/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention_layer_norm/gamma:0: Tensor("norm_83/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/self_attention_layer_norm/beta:0: Tensor("norm_84/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/intermediate/kernel:0: Tensor("norm_85/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/intermediate/bias:0: Tensor("norm_86/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output/kernel:0: Tensor("norm_87/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output/bias:0: Tensor("norm_88/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output_layer_norm/gamma:0: Tensor("norm_89/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_2/output_layer_norm/beta:0: Tensor("norm_90/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/query/kernel:0: Tensor("norm_91/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/key/kernel:0: Tensor("norm_92/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/value/kernel:0: Tensor("norm_93/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention/attention_output/kernel:0: Tensor("norm_94/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention_layer_norm/gamma:0: Tensor("norm_95/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/self_attention_layer_norm/beta:0: Tensor("norm_96/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/intermediate/kernel:0: Tensor("norm_97/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/intermediate/bias:0: Tensor("norm_98/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output/kernel:0: Tensor("norm_99/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output/bias:0: Tensor("norm_100/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output_layer_norm/gamma:0: Tensor("norm_101/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_3/output_layer_norm/beta:0: Tensor("norm_102/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/query/kernel:0: Tensor("norm_103/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/key/kernel:0: Tensor("norm_104/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/value/kernel:0: Tensor("norm_105/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention/attention_output/kernel:0: Tensor("norm_106/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention_layer_norm/gamma:0: Tensor("norm_107/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/self_attention_layer_norm/beta:0: Tensor("norm_108/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/intermediate/kernel:0: Tensor("norm_109/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/intermediate/bias:0: Tensor("norm_110/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output/kernel:0: Tensor("norm_111/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output/bias:0: Tensor("norm_112/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output_layer_norm/gamma:0: Tensor("norm_113/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_4/output_layer_norm/beta:0: Tensor("norm_114/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/query/kernel:0: Tensor("norm_115/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/key/kernel:0: Tensor("norm_116/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/value/kernel:0: Tensor("norm_117/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention/attention_output/kernel:0: Tensor("norm_118/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention_layer_norm/gamma:0: Tensor("norm_119/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/self_attention_layer_norm/beta:0: Tensor("norm_120/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/intermediate/kernel:0: Tensor("norm_121/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/intermediate/bias:0: Tensor("norm_122/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output/kernel:0: Tensor("norm_123/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output/bias:0: Tensor("norm_124/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output_layer_norm/gamma:0: Tensor("norm_125/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_5/output_layer_norm/beta:0: Tensor("norm_126/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_normalization/gamma:0: Tensor("norm_127/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_encoder/layer_normalization/beta:0: Tensor("norm_128/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/query/kernel:0: Tensor("norm_129/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/key/kernel:0: Tensor("norm_130/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/value/kernel:0: Tensor("norm_131/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention/attention_output/kernel:0: Tensor("norm_132/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention_layer_norm/gamma:0: Tensor("norm_133/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/self_attention_layer_norm/beta:0: Tensor("norm_134/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/query/kernel:0: Tensor("norm_135/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/key/kernel:0: Tensor("norm_136/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/value/kernel:0: Tensor("norm_137/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec/attention_output/kernel:0: Tensor("norm_138/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_139/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/attention/encdec_output_layer_norm/beta:0: Tensor("norm_140/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/intermediate/kernel:0: Tensor("norm_141/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/intermediate/bias:0: Tensor("norm_142/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output/kernel:0: Tensor("norm_143/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output/bias:0: Tensor("norm_144/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output_layer_norm/gamma:0: Tensor("norm_145/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_0/output_layer_norm/beta:0: Tensor("norm_146/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/query/kernel:0: Tensor("norm_147/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/key/kernel:0: Tensor("norm_148/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/value/kernel:0: Tensor("norm_149/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention/attention_output/kernel:0: Tensor("norm_150/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention_layer_norm/gamma:0: Tensor("norm_151/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/self_attention_layer_norm/beta:0: Tensor("norm_152/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/query/kernel:0: Tensor("norm_153/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/key/kernel:0: Tensor("norm_154/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/value/kernel:0: Tensor("norm_155/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec/attention_output/kernel:0: Tensor("norm_156/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_157/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/attention/encdec_output_layer_norm/beta:0: Tensor("norm_158/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/intermediate/kernel:0: Tensor("norm_159/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/intermediate/bias:0: Tensor("norm_160/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output/kernel:0: Tensor("norm_161/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output/bias:0: Tensor("norm_162/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output_layer_norm/gamma:0: Tensor("norm_163/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_1/output_layer_norm/beta:0: Tensor("norm_164/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/query/kernel:0: Tensor("norm_165/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/key/kernel:0: Tensor("norm_166/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/value/kernel:0: Tensor("norm_167/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention/attention_output/kernel:0: Tensor("norm_168/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention_layer_norm/gamma:0: Tensor("norm_169/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/self_attention_layer_norm/beta:0: Tensor("norm_170/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/query/kernel:0: Tensor("norm_171/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/key/kernel:0: Tensor("norm_172/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/value/kernel:0: Tensor("norm_173/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec/attention_output/kernel:0: Tensor("norm_174/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_175/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/attention/encdec_output_layer_norm/beta:0: Tensor("norm_176/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/intermediate/kernel:0: Tensor("norm_177/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/intermediate/bias:0: Tensor("norm_178/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output/kernel:0: Tensor("norm_179/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output/bias:0: Tensor("norm_180/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output_layer_norm/gamma:0: Tensor("norm_181/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_2/output_layer_norm/beta:0: Tensor("norm_182/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/query/kernel:0: Tensor("norm_183/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/key/kernel:0: Tensor("norm_184/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/value/kernel:0: Tensor("norm_185/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention/attention_output/kernel:0: Tensor("norm_186/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention_layer_norm/gamma:0: Tensor("norm_187/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/self_attention_layer_norm/beta:0: Tensor("norm_188/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/query/kernel:0: Tensor("norm_189/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/key/kernel:0: Tensor("norm_190/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/value/kernel:0: Tensor("norm_191/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec/attention_output/kernel:0: Tensor("norm_192/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec_output_layer_norm/gamma:0: Tensor("norm_193/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/attention/encdec_output_layer_norm/beta:0: Tensor("norm_194/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/intermediate/kernel:0: Tensor("norm_195/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/intermediate/bias:0: Tensor("norm_196/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output/kernel:0: Tensor("norm_197/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output/bias:0: Tensor("norm_198/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output_layer_norm/gamma:0: Tensor("norm_199/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_3/output_layer_norm/beta:0: Tensor("norm_200/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/query/kernel:0: Tensor("norm_201/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/key/kernel:0: Tensor("norm_202/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/value/kernel:0: Tensor("norm_203/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention/attention_output/kernel:0: Tensor("norm_204/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention_layer_norm/gamma:0: Tensor("norm_205/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/self_attention_layer_norm/beta:0: Tensor("norm_206/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Gradient norm for param detr_transformer/transformer_decoder/layer_4/attention/encdec/query/kernel:0: Tensor("norm_207/Squeeze:0", shape=(), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
Calculating gradients....
Applying gradients....
